{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. setting up packages and loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d2469361314adcb9bc81572dc5a25f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 14:19:06 INFO: Downloaded file to C:\\Users\\omarm\\stanza_resources\\resources.json\n",
      "2024-04-12 14:19:06 INFO: Downloading default packages for language: en (English) ...\n",
      "2024-04-12 14:19:07 INFO: File exists: C:\\Users\\omarm\\stanza_resources\\en\\default.zip\n",
      "2024-04-12 14:19:09 INFO: Finished downloading models and saved to C:\\Users\\omarm\\stanza_resources\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\omarm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\omarm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2024-04-12 14:22:38 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e466cd0c26b424eacd87a0591670000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 14:22:39 INFO: Downloaded file to C:\\Users\\omarm\\stanza_resources\\resources.json\n",
      "2024-04-12 14:22:39 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n",
      "2024-04-12 14:22:39 INFO: Using device: cpu\n",
      "2024-04-12 14:22:39 INFO: Loading: tokenize\n",
      "2024-04-12 14:22:39 INFO: Loading: mwt\n",
      "2024-04-12 14:22:39 INFO: Loading: lemma\n",
      "2024-04-12 14:22:39 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import gensim.downloader as api\n",
    "\n",
    "\n",
    "stanza.download('en')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "word2vec = api.load('word2vec-google-news-300') #? 3M vocab - 1.66GB\n",
    "fastText = api.load('fasttext-wiki-news-subwords-300') #? 1M vocab - 0.96GB \n",
    "glove = api.load('glove-wiki-gigaword-300') #? 400K vocab - 0.37GB\n",
    "\n",
    "spacy_nlp = spacy.load('en_core_web_sm')\n",
    "stanza_pipe = stanza.Pipeline(lang='en', processors='tokenize, lemma, mwt', use_gpu=False)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "info = []\n",
    "test_path,train_path = 'data/testing/', 'data/training/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()\n",
    "\n",
    "def get_time():\n",
    "  return time.ctime().split(' ')[3]\n",
    "\n",
    "def debug_msg(str):\n",
    "  print(f\"{len(info)+1}- {get_time()} {str}\")\n",
    "  info.append(f\"{len(info)+1}- {get_time()} {str}\")\n",
    "\n",
    "def get_classes(train_data, loc) -> dict[str, dict]:\n",
    "  class_results = {}\n",
    "  for i in range(len(train_data)):\n",
    "    if train_data[i] != '.DS_Store':\n",
    "      class_results[train_data[i]] = {\n",
    "        'files' : os.listdir(f'{loc}{train_data[i]}'),\n",
    "      }\n",
    "  # debug_msg(f\"number of {loc} classes: {len(class_results)}\")\n",
    "  return class_results\n",
    "\n",
    "def filter_text(data) -> str:\n",
    "  mod_data = data.replace('\\n', ' ').lower()\n",
    "  split_mod_data = re.split('[ ,.\\'\\\"><]+', mod_data)\n",
    "  filtered_data = ' '.join([w for w in split_mod_data if (not w in stop_words) and (len(w) > 1)])\n",
    "  return filtered_data\n",
    "\n",
    "def get_docs(classes, loc, limit_ratio=1):\n",
    "  data = []\n",
    "  for c in classes:\n",
    "    if limit_ratio != 1:\n",
    "      class_limit = len(classes[c]['files']) * limit_ratio\n",
    "    for idx, f in enumerate(classes[c]['files']):\n",
    "      with open(f'{loc}{c}/{f}', 'r', encoding='latin-1') as file:\n",
    "        filtered_data = filter_text(file.read())\n",
    "        data.append({'class': c, 'text': filtered_data })\n",
    "      if limit_ratio != 1 and idx > class_limit:\n",
    "        break\n",
    "  if limit_ratio != 1:\n",
    "    debug_msg(f\"using {limit_ratio*100}% of {loc} data. number of documents: {len(data)}\")\n",
    "  else:\n",
    "    debug_msg(f\"using all of {loc} data. number of documents: {len(data)}\")\n",
    "  return data\n",
    "\n",
    "def stanza_tokenizer(data) -> dict[list[str], dict]:\n",
    "  debug_msg(f\"START: tokenizing text using stanza...\")\n",
    "\n",
    "  stanza_docs = [stanza.Document([], text=d) for d in [t['text'] for t in data]]\n",
    "  tkn_docs = stanza_pipe(stanza_docs) #? time consuming...\n",
    "  tokens = [[word.lemma for word in sentence.words] for doc in tkn_docs for sentence in doc.sentences] \n",
    "  flat_tokens = [item for sublist in tokens for item in sublist]\n",
    "  count_vec = vec.fit(flat_tokens).vocabulary_\n",
    "\n",
    "  debug_msg(f\"COMPLETED: tokenizing text using stanza ({len(flat_tokens)} tokens), vocab size: {len(count_vec)} tokens\")\n",
    "  return { 'tokens': flat_tokens, 'counts_vec': count_vec }\n",
    "\n",
    "def spacy_tokenizer(data) -> dict[list[str], dict]:\n",
    "  debug_msg(f\"START: tokenizing text using spacy...\")\n",
    "\n",
    "  spacy_docs = [spacy_nlp(t['text']) for t in tqdm(data)] #? time consuming...\n",
    "  tokens = [[token.text for token in doc] for doc in spacy_docs]\n",
    "  flat_tokens = [item for sublist in tokens for item in sublist]\n",
    "  count_vec = vec.fit(flat_tokens).vocabulary_\n",
    "\n",
    "  debug_msg(f\"COMPLETED: tokenizing text using spacy ({len(flat_tokens)} tokens), vocab size: {len(count_vec)} tokens\")\n",
    "  return {'tokens': flat_tokens, 'counts_vec': count_vec }\n",
    "\n",
    "def get_lemma_docs(data) -> list[dict]:\n",
    "  lemma_docs = []\n",
    "  for d in tqdm(data):\n",
    "    f_doc = filter_text(d['text'])\n",
    "    lemmas = spacy_nlp(f_doc)\n",
    "    lemma_doc = ' '.join([token.lemma_ for token in lemmas])\n",
    "    lemma_docs.append({'class': d['class'], 'text': lemma_doc})\n",
    "\n",
    "  debug_msg(f\"COMPLETED: lemmatizing text\")\n",
    "  return lemma_docs\n",
    "\n",
    "def docs_from_path(path, limit_per) -> pd.DataFrame:\n",
    "  data_path = os.listdir(path)\n",
    "  classes = get_classes(data_path, loc=path)\n",
    "  docs = get_docs(classes, loc=path, limit_ratio=limit_per)\n",
    "  # debug_msg(f\"START: lemmatizing docs text...\") \n",
    "  # lemma_docs = get_lemma_docs(docs) #* wasn't helpful\n",
    "\n",
    "  return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1- 13:27:08 using all of data/training/ data. number of documents: 11413\n",
      "2- 13:27:09 using all of data/testing/ data. number of documents: 4024\n"
     ]
    }
   ],
   "source": [
    "train = docs_from_path(train_path, limit_per=1)\n",
    "test = docs_from_path(test_path, limit_per=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Naive Bayes [from scratch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def naive_bayes(train_docs, test_docs):\n",
    "  debug_msg(f\"START: training naive bayes model...\")\n",
    "  train_df = pd.DataFrame(train_docs)\n",
    "  tokens_data = spacy_tokenizer(train_docs) #* spacy tokenizer\n",
    "  # tokens_data = stanza_tokenizer(train_docs) #* stanza tokenizer\n",
    "  tokens_size, vocab_size = len(tokens_data['tokens']), len(tokens_data['counts_vec'])\n",
    "  word_prob_cache = {}\n",
    "  \n",
    "  def class_words(c):\n",
    "    counts = vec.fit_transform(c['text'])\n",
    "    word_count = counts.sum(axis=0)\n",
    "    df = pd.DataFrame(word_count, columns=vec.get_feature_names_out())\n",
    "    return df\n",
    "\n",
    "  def word_prob(word, c):\n",
    "    if (word, c) in word_prob_cache:\n",
    "      return word_prob_cache[(word, c)]\n",
    "    try:\n",
    "      word_sum = df_word_count[word][c].sum()\n",
    "    except:\n",
    "      word_sum = 0\n",
    "    try:\n",
    "      all_sum = df_word_count[word].sum()\n",
    "    except:\n",
    "      all_sum = tokens_size\n",
    "    res = (word_sum + 1) / (all_sum + vocab_size)\n",
    "\n",
    "    word_prob_cache[(word, c)] = res\n",
    "    return res\n",
    "\n",
    "  def prop_sentence(sentence, c):\n",
    "    words = sentence.split(' ')\n",
    "    prob = 1\n",
    "    for word in words:\n",
    "      prob *= word_prob(word, c)\n",
    "    return prob * priors[c]\n",
    "\n",
    "  def max_class(doc)-> str:\n",
    "    new_doc = filter_text(doc)\n",
    "    # tokens = spacy_nlp(filtered_doc) #* spacy tokenizer -1\n",
    "    # new_doc = ' '.join([token.text for token in tokens]) #* spacy tokenizer -2\n",
    "    \n",
    "    # new_tokens = stanza_pipe(filtered_doc) #* stanza tokenizer -1\n",
    "    # new_doc = ' '.join([word.lemma for word in new_tokens.sentences[0].words]) #* stanza tokenizer -2\n",
    "\n",
    "    probs = {}\n",
    "    for c in train_df['class'].unique():\n",
    "      probs[c] = prop_sentence(new_doc, c)\n",
    "    max_class = max(probs, key=probs.get)\n",
    "    return max_class\n",
    "\n",
    "  debug_msg(f\"Preparing Naive Bayes Parameters...\")\n",
    "  priors = train_df['class'].value_counts(normalize=True)\n",
    "  df_word_count = train_df.groupby('class').apply(class_words)\n",
    "  \n",
    "  debug_msg(f\"Applying naive bayes model on Test Data...\")\n",
    "  result_df = pd.DataFrame(test_docs)\n",
    "  tqdm.pandas()\n",
    "  result_df['predicted'] = result_df['text'].progress_apply(max_class)\n",
    "  \n",
    "  debug_msg(f\"COMPLETED: testing naive bayes model...\")\n",
    "  f1 = round(f1_score(result_df['class'], result_df['predicted'], average='macro')*100, 2)\n",
    "  acc = round(accuracy_score(result_df['class'], result_df['predicted'])*100, 2)\n",
    "  return { 'model': 'Manual NB', 'F1 Score': f1, 'Avg Accuracy': acc }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"sample class files: {all_classes['tin']}\")\n",
    "# print(f\"train sample: {train[0]}\")\n",
    "# print(f\"test sample: {test[0]}\")\n",
    "# print(f\"stanza train sample: {len(stanza_data)}\")\n",
    "# print(f\"spacy tokens: {spacy_data['tokens'][:10]},\\nvocab: {spacy_data['vocab']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3- 02:48:58 START: training naive bayes model...\n",
      "4- 02:48:58 START: tokenizing text using spacy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11413/11413 [02:49<00:00, 67.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5- 02:51:50 COMPLETED: tokenizing text using spacy (1414367 tokens), vocab size: 29578 tokens\n",
      "6- 02:51:51 Preparing Naive Bayes Parameters...\n",
      "7- 02:52:18 Applying naive bayes model on Test Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4024/4024 [04:27<00:00, 15.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8- 02:56:45 COMPLETED: testing naive bayes model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'Manual NB', 'F1 Score': 3.63, 'Avg Accuracy': 48.56}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scratch_nb = naive_bayes(train, test)\n",
    "scratch_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Naive bayes [sklearn] using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'Sklearn NB', 'F1 Score': 13.09, 'Avg Accuracy': 68.32}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df = pd.DataFrame(train)\n",
    "test_df = pd.DataFrame(test)\n",
    "\n",
    "#* splitting the data\n",
    "vec_fit = vec.fit_transform(train_df['text'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(vec_fit, train_df['class'], test_size=0.001, random_state=42)\n",
    "X_test = vec.transform(test_df['text'])\n",
    "y_test = test_df['class']\n",
    "\n",
    "#* fitting the model\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "accuracy = round(accuracy_score(y_test, y_pred) *100, 2)\n",
    "f1 = round(f1_score(y_test, y_pred, average='macro') *100, 2)\n",
    "\n",
    "nb_results = { 'model': 'Sklearn NB', 'F1 Score': f1, 'Avg Accuracy': accuracy }\n",
    "nb_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Naive bayes [sklearn] using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'TF-IDF NB', 'F1 Score': 3.97, 'Avg Accuracy': 53.23}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying tf-idf with naive bayes\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "vec_fit = tfidf.fit_transform(train_df['text'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vec_fit, train_df['class'], test_size=0.001, random_state=1234)\n",
    "X_test = tfidf.transform(test_df['text'])\n",
    "y_test = test_df['class']\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "f1 = round(f1_score(y_test, y_pred, average='macro')*100, 2)\n",
    "\n",
    "tfidf_nb_results = { 'model': 'TF-IDF NB', 'F1 Score': f1, 'Avg Accuracy': accuracy }\n",
    "tfidf_nb_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train)\n",
    "test_df = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4- 14:54:57 Preparing word vectors for 11413 docs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11413/11413 [00:08<00:00, 1364.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5- 14:55:06 Preparing word vectors for 4024 docs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4024/4024 [00:02<00:00, 1368.53it/s]\n",
      "c:\\Users\\omarm\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'Logistic Regression', 'F1 Score': 1.57, 'Avg Accuracy': 39.49}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "from nltk import word_tokenize\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "#* returns a sequence of n-gram strings from string as list\n",
    "def gen_ngrams(text, grams=2) -> list:\n",
    "  n_grams = ngrams(word_tokenize(text), grams)\n",
    "  n_grams_list = [' '.join(g) for g in n_grams]\n",
    "  return n_grams_list\n",
    "\n",
    "#* returns a list of lemmatized tokens\n",
    "def ngrams_prep(text, n=1) -> list:\n",
    "  words = [w for w in word_tokenize(text.lower())]\n",
    "  fn_grams = gen_ngrams(' '.join(words), n)\n",
    "  # lemmas = [spacy_nlp(w)[0].lemma_ for w in fn_grams]\n",
    "  return fn_grams\n",
    "\n",
    "def docs_to_vecs(docs) -> list:\n",
    "  docs_grams = [ngrams_prep(doc, n=1) for doc in docs]\n",
    "  docs_vecs = []\n",
    "\n",
    "  debug_msg(f\"Preparing word vectors for {len(docs_grams)} docs...\")\n",
    "  for doc in tqdm(docs):\n",
    "    words_vec = []\n",
    "    for word in doc:\n",
    "      if word in fastText:\n",
    "        words_vec.append(fastText[word]) #* adding train word vector to the list\n",
    "\n",
    "    if len(words_vec) == 0: #* if no word vector found, add a zero vector\n",
    "      words_vec.append(np.zeros(300))\n",
    "    docs_vecs.append(np.mean(words_vec, axis=0)) #* combine all word_vecs using mean between them\n",
    "  return docs_vecs\n",
    "\n",
    "X_train = docs_to_vecs(train_df['text'])\n",
    "X_test = docs_to_vecs(test_df['text'])\n",
    "\n",
    "y_train = train_df['class']\n",
    "y_test = test_df['class']\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "f1_score = round(f1_score(y_test, y_pred, average='macro')*100, 2)\n",
    "accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "\n",
    "logistic_results = { 'model': 'Logistic Regression', 'F1 Score': f1_score, 'Avg Accuracy': accuracy }\n",
    "logistic_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy = {\n",
    "  'model': 'Manual NB', 'F1 Score': 3.57, 'Avg Accuracy': 50.67, 'time': '07:32', 'tokens': 29533,\n",
    "}\n",
    "\n",
    "spacy_exclamation = { \n",
    "  'model': 'Manual NB', 'F1 Score': 3.63, 'Avg Accuracy': 48.56\n",
    "}\n",
    "\n",
    "stanza = {\n",
    "  'model': 'Manual NB', 'F1 Score': 3.48, 'Avg Accuracy': 49.65,'time': '10:09','tokens': 25123,\n",
    "}\n",
    "\n",
    "sklearn = {\n",
    "  'model': 'Sklearn NB', 'F1 Score': 13.37, 'Avg Accuracy': 68.59, 'time': '00:01'\n",
    "}\n",
    "\n",
    "# applied lemmas to use text\n",
    "sklearn_lemma_docs = {\n",
    "  'model': 'Sklearn NB', 'F1 Score': 13.09, 'Avg Accuracy': 68.32\n",
    "}\n",
    "\n",
    "tfidf = {\n",
    "  'model': 'TF-IDF NB', 'F1 Score': 4.08, 'Avg Accuracy': 54.10\n",
    "}\n",
    "# all these need re-running\n",
    "{'model': 'Logistic Regression - Glove', 'F1 Score': 2.98, 'Avg Accuracy': 43.34}\n",
    "\n",
    "{'model': 'Logistic Regression - w2v ', 'F1 Score': 1.91, 'Avg Accuracy': 40.95}\n",
    "\n",
    "{'model': 'Logistic Regression - fasttext', 'F1 Score': 1.57, 'Avg Accuracy': 39.49}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
